{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656ecd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langdetect googletrans==4.0.0-rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aca65b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from string import punctuation\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import resample\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from langdetect import detect\n",
    "from googletrans import Translator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd031a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_data = pd.read_csv(\"C:/Users/Vasu/Desktop/API projects/youtube_api/youtube_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b68e4e76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>channelTitle</th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "      <th>description</th>\n",
       "      <th>viewCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>commentCount</th>\n",
       "      <th>duration</th>\n",
       "      <th>definition</th>\n",
       "      <th>caption</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>day</th>\n",
       "      <th>tag_count</th>\n",
       "      <th>title_length</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v_lQaB7zgIA</td>\n",
       "      <td>Nakkalites</td>\n",
       "      <td>Short Trip-à®† à®šà¯‹à®¤à®¿à®•à¯à®•à®¾à®¤à®¿à®™à¯à®• DağŸ˜’ | Nakkalites #s...</td>\n",
       "      <td>['nakkalites channel', 'nakkalites new video',...</td>\n",
       "      <td>For Business \\nContact us - business@nakkalite...</td>\n",
       "      <td>14269</td>\n",
       "      <td>1472</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0m 53s</td>\n",
       "      <td>hd</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>12:30:45</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>25</td>\n",
       "      <td>51</td>\n",
       "      <td>['Super comedy ğŸ˜‚', 'Super video ğŸ˜‚']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lXjEFmq-qfw</td>\n",
       "      <td>Nakkalites</td>\n",
       "      <td>à®‡à®¤à®¾à®©à¯ Rough &amp; Tough Dealing-à®†ğŸ˜‚ | Nakkalites #s...</td>\n",
       "      <td>['Nakkalites', 'nakkalites new video', 'amma a...</td>\n",
       "      <td>For Business \\nContact us - business@nakkalite...</td>\n",
       "      <td>10948</td>\n",
       "      <td>732</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0m 55s</td>\n",
       "      <td>hd</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>08:30:24</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>28</td>\n",
       "      <td>51</td>\n",
       "      <td>['Please pin me bro ğŸ‰ğŸ‰ğŸ‰ğŸ‰']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q8kWxKCJCZo</td>\n",
       "      <td>Nakkalites</td>\n",
       "      <td>à®à®©à¯à®©à®Ÿà®¾ à®ªà¯Šà®šà¯à®•à¯à®•à¯à®©à¯à®©à¯ Uncle-à®©à¯ à®šà¯Šà®²à¯à®²à®¿à®Ÿà¯à®Ÿà¯€à®™à¯à®•ğŸ™„ğŸ˜’ |...</td>\n",
       "      <td>['nakkalites channel', 'nakkalites new video',...</td>\n",
       "      <td>For Business \\nContact us - business@nakkalite...</td>\n",
       "      <td>14287</td>\n",
       "      <td>1372</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0m 35s</td>\n",
       "      <td>hd</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-07-30</td>\n",
       "      <td>12:30:17</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>25</td>\n",
       "      <td>65</td>\n",
       "      <td>['Bro I am watch group photo i am cry bro', 'B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R8Viun7HeAM</td>\n",
       "      <td>Nakkalites</td>\n",
       "      <td>à®…à®µà®© à®µà®¿à®Ÿà¯à®°à¯à®™à¯à®• à®à®©à¯à®© à®®à®Ÿà¯à®Ÿà¯à®®à¯ à®•à¯‡à®Ÿà¯à®Ÿà¯à®Ÿà¯à®Ÿà¯‡ à®‡à®°à¯à®™à¯à®• |...</td>\n",
       "      <td>['Nakkalites', 'nakkalites new video', 'amma a...</td>\n",
       "      <td>For Business \\nContact us - business@nakkalite...</td>\n",
       "      <td>17704</td>\n",
       "      <td>872</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0m 50s</td>\n",
       "      <td>hd</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-07-30</td>\n",
       "      <td>08:30:14</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>28</td>\n",
       "      <td>65</td>\n",
       "      <td>['Pin meğŸ‰ğŸ‰ğŸ‰ğŸ‰', 'Vintage nakkalites laam chance...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oAL7sMhfOZ0</td>\n",
       "      <td>Nakkalites</td>\n",
       "      <td>à®šà®¿à®©à¯à®© à®ªà®šà®™à¯à®•à®³à®¾à®®à¯ à®ªà¯à®£à¯à®ªà®Ÿà¯à®¤à¯à®¤à¯à®±à®¾à®™à¯à®•à®³à¯‡ğŸ˜’ | Nakkalit...</td>\n",
       "      <td>['nakkalites channel', 'nakkalites new video',...</td>\n",
       "      <td>For Business \\nContact us - business@nakkalite...</td>\n",
       "      <td>14631</td>\n",
       "      <td>1180</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0m 44s</td>\n",
       "      <td>hd</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>12:30:41</td>\n",
       "      <td>Monday</td>\n",
       "      <td>25</td>\n",
       "      <td>56</td>\n",
       "      <td>['Pin me', 'Sasi and arun combo v want back', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>chYndzcBx_c</td>\n",
       "      <td>Nakkalites</td>\n",
       "      <td>à®®à®¾à®ªà¯à®³ à®¨à¯€à®¯à¯à®®à¯ à®…à®¤ à®šà¯Šà®²à¯à®²à®¾à®¤ Da | Nakkalites #shorts</td>\n",
       "      <td>['Nakkalites', 'nakkalites new video', 'amma a...</td>\n",
       "      <td>For Business \\nContact us - business@nakkalite...</td>\n",
       "      <td>15785</td>\n",
       "      <td>1399</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0m 44s</td>\n",
       "      <td>hd</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>08:30:11</td>\n",
       "      <td>Monday</td>\n",
       "      <td>28</td>\n",
       "      <td>47</td>\n",
       "      <td>['ğŸ¤—', 'Nakkalites back tooo form ahhhğŸ’•ğŸ˜˜ğŸ’•ğŸ’•ğŸ’•â¤â¤â¤â¤...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pEOV3N8FzdY</td>\n",
       "      <td>Nakkalites</td>\n",
       "      <td>à®ªà¯‹à®±à¯‹à®®à¯ à®¤à¯†à®±à®¿à®•à¯à®• à®µà®¿à®Ÿà¯à®±à¯‹à®®à¯ | Nakkalites #shorts</td>\n",
       "      <td>['Nakkalites', 'nakkalites new video', 'amma a...</td>\n",
       "      <td>For Business \\nContact us - business@nakkalite...</td>\n",
       "      <td>8355</td>\n",
       "      <td>654</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0m 50s</td>\n",
       "      <td>hd</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-07-28</td>\n",
       "      <td>12:30:29</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>28</td>\n",
       "      <td>44</td>\n",
       "      <td>['First â¤ğŸ‰']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XbEsBMxSQMc</td>\n",
       "      <td>Nakkalites</td>\n",
       "      <td>à®…à®Ÿà¯à®¤à¯à®¤ à®šà®®à¯à®ªà®µà®®à¯ à®‡à®°à¯à®•à¯à®•à¯ | Nakkalites #shorts</td>\n",
       "      <td>['nakkalites', 'nakkalites latest', 'nakkalite...</td>\n",
       "      <td>For Business \\nContact us - business@nakkalite...</td>\n",
       "      <td>30462</td>\n",
       "      <td>1800</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0m 45s</td>\n",
       "      <td>hd</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-07-28</td>\n",
       "      <td>08:30:09</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>25</td>\n",
       "      <td>43</td>\n",
       "      <td>['ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚', 'Adutha Aapu Udane Nanbanukku thağŸ˜‚', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PJbnDENJUQE</td>\n",
       "      <td>Nakkalites</td>\n",
       "      <td>à®…à®Ÿà®¿à®ªà¯à®ªà®¾à®µà®¿ à®…à®ªà¯à®ªà¯‹ à®šà¯Šà®©à¯à®©à®¤à¯à®²à®¾à®®à¯ à®ªà¯Šà®¯à¯-à®† |  Nakkalit...</td>\n",
       "      <td>['Nakkalites', 'nakkalites new video', 'amma a...</td>\n",
       "      <td>For Business \\nContact us - business@nakkalite...</td>\n",
       "      <td>25318</td>\n",
       "      <td>1491</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0m 36s</td>\n",
       "      <td>hd</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-07-27</td>\n",
       "      <td>12:30:24</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>28</td>\n",
       "      <td>56</td>\n",
       "      <td>['ğŸ˜‚ğŸ˜‚ğŸ˜‚', 'Hi ashwin, Amit this side  I liked wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>o0yu7ueG_pI</td>\n",
       "      <td>Nakkalites</td>\n",
       "      <td>à®…à®µà®©à¯à®™à¯à®• à®…à®ªà¯à®Ÿà®¿ à®ªà®£à¯à®£ à®®à®¾à®Ÿà¯à®Ÿà®¾à®™à¯à®•à®³à¯‡ | Nakkalites #s...</td>\n",
       "      <td>['nakkalites', 'nakkalites latest', 'nakkalite...</td>\n",
       "      <td>For Business \\nContact us - business@nakkalite...</td>\n",
       "      <td>42157</td>\n",
       "      <td>3916</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0m 54s</td>\n",
       "      <td>hd</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-07-27</td>\n",
       "      <td>08:30:13</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>25</td>\n",
       "      <td>51</td>\n",
       "      <td>['SuperğŸ˜‚']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id channelTitle  \\\n",
       "0  v_lQaB7zgIA   Nakkalites   \n",
       "1  lXjEFmq-qfw   Nakkalites   \n",
       "2  Q8kWxKCJCZo   Nakkalites   \n",
       "3  R8Viun7HeAM   Nakkalites   \n",
       "4  oAL7sMhfOZ0   Nakkalites   \n",
       "5  chYndzcBx_c   Nakkalites   \n",
       "6  pEOV3N8FzdY   Nakkalites   \n",
       "7  XbEsBMxSQMc   Nakkalites   \n",
       "8  PJbnDENJUQE   Nakkalites   \n",
       "9  o0yu7ueG_pI   Nakkalites   \n",
       "\n",
       "                                               title  \\\n",
       "0  Short Trip-à®† à®šà¯‹à®¤à®¿à®•à¯à®•à®¾à®¤à®¿à®™à¯à®• DağŸ˜’ | Nakkalites #s...   \n",
       "1  à®‡à®¤à®¾à®©à¯ Rough & Tough Dealing-à®†ğŸ˜‚ | Nakkalites #s...   \n",
       "2  à®à®©à¯à®©à®Ÿà®¾ à®ªà¯Šà®šà¯à®•à¯à®•à¯à®©à¯à®©à¯ Uncle-à®©à¯ à®šà¯Šà®²à¯à®²à®¿à®Ÿà¯à®Ÿà¯€à®™à¯à®•ğŸ™„ğŸ˜’ |...   \n",
       "3  à®…à®µà®© à®µà®¿à®Ÿà¯à®°à¯à®™à¯à®• à®à®©à¯à®© à®®à®Ÿà¯à®Ÿà¯à®®à¯ à®•à¯‡à®Ÿà¯à®Ÿà¯à®Ÿà¯à®Ÿà¯‡ à®‡à®°à¯à®™à¯à®• |...   \n",
       "4  à®šà®¿à®©à¯à®© à®ªà®šà®™à¯à®•à®³à®¾à®®à¯ à®ªà¯à®£à¯à®ªà®Ÿà¯à®¤à¯à®¤à¯à®±à®¾à®™à¯à®•à®³à¯‡ğŸ˜’ | Nakkalit...   \n",
       "5    à®®à®¾à®ªà¯à®³ à®¨à¯€à®¯à¯à®®à¯ à®…à®¤ à®šà¯Šà®²à¯à®²à®¾à®¤ Da | Nakkalites #shorts   \n",
       "6       à®ªà¯‹à®±à¯‹à®®à¯ à®¤à¯†à®±à®¿à®•à¯à®• à®µà®¿à®Ÿà¯à®±à¯‹à®®à¯ | Nakkalites #shorts   \n",
       "7        à®…à®Ÿà¯à®¤à¯à®¤ à®šà®®à¯à®ªà®µà®®à¯ à®‡à®°à¯à®•à¯à®•à¯ | Nakkalites #shorts   \n",
       "8  à®…à®Ÿà®¿à®ªà¯à®ªà®¾à®µà®¿ à®…à®ªà¯à®ªà¯‹ à®šà¯Šà®©à¯à®©à®¤à¯à®²à®¾à®®à¯ à®ªà¯Šà®¯à¯-à®† |  Nakkalit...   \n",
       "9  à®…à®µà®©à¯à®™à¯à®• à®…à®ªà¯à®Ÿà®¿ à®ªà®£à¯à®£ à®®à®¾à®Ÿà¯à®Ÿà®¾à®™à¯à®•à®³à¯‡ | Nakkalites #s...   \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['nakkalites channel', 'nakkalites new video',...   \n",
       "1  ['Nakkalites', 'nakkalites new video', 'amma a...   \n",
       "2  ['nakkalites channel', 'nakkalites new video',...   \n",
       "3  ['Nakkalites', 'nakkalites new video', 'amma a...   \n",
       "4  ['nakkalites channel', 'nakkalites new video',...   \n",
       "5  ['Nakkalites', 'nakkalites new video', 'amma a...   \n",
       "6  ['Nakkalites', 'nakkalites new video', 'amma a...   \n",
       "7  ['nakkalites', 'nakkalites latest', 'nakkalite...   \n",
       "8  ['Nakkalites', 'nakkalites new video', 'amma a...   \n",
       "9  ['nakkalites', 'nakkalites latest', 'nakkalite...   \n",
       "\n",
       "                                         description  viewCount  likeCount  \\\n",
       "0  For Business \\nContact us - business@nakkalite...      14269       1472   \n",
       "1  For Business \\nContact us - business@nakkalite...      10948        732   \n",
       "2  For Business \\nContact us - business@nakkalite...      14287       1372   \n",
       "3  For Business \\nContact us - business@nakkalite...      17704        872   \n",
       "4  For Business \\nContact us - business@nakkalite...      14631       1180   \n",
       "5  For Business \\nContact us - business@nakkalite...      15785       1399   \n",
       "6  For Business \\nContact us - business@nakkalite...       8355        654   \n",
       "7  For Business \\nContact us - business@nakkalite...      30462       1800   \n",
       "8  For Business \\nContact us - business@nakkalite...      25318       1491   \n",
       "9  For Business \\nContact us - business@nakkalite...      42157       3916   \n",
       "\n",
       "   commentCount duration definition  caption        date      time        day  \\\n",
       "0           2.0   0m 53s         hd    False  2024-07-31  12:30:45  Wednesday   \n",
       "1           1.0   0m 55s         hd    False  2024-07-31  08:30:24  Wednesday   \n",
       "2           7.0   0m 35s         hd    False  2024-07-30  12:30:17    Tuesday   \n",
       "3           3.0   0m 50s         hd    False  2024-07-30  08:30:14    Tuesday   \n",
       "4           3.0   0m 44s         hd    False  2024-07-29  12:30:41     Monday   \n",
       "5           3.0   0m 44s         hd    False  2024-07-29  08:30:11     Monday   \n",
       "6           1.0   0m 50s         hd    False  2024-07-28  12:30:29     Sunday   \n",
       "7           3.0   0m 45s         hd    False  2024-07-28  08:30:09     Sunday   \n",
       "8           3.0   0m 36s         hd    False  2024-07-27  12:30:24   Saturday   \n",
       "9           1.0   0m 54s         hd    False  2024-07-27  08:30:13   Saturday   \n",
       "\n",
       "   tag_count  title_length                                           comments  \n",
       "0         25            51                ['Super comedy ğŸ˜‚', 'Super video ğŸ˜‚']  \n",
       "1         28            51                         ['Please pin me bro ğŸ‰ğŸ‰ğŸ‰ğŸ‰']  \n",
       "2         25            65  ['Bro I am watch group photo i am cry bro', 'B...  \n",
       "3         28            65  ['Pin meğŸ‰ğŸ‰ğŸ‰ğŸ‰', 'Vintage nakkalites laam chance...  \n",
       "4         25            56  ['Pin me', 'Sasi and arun combo v want back', ...  \n",
       "5         28            47  ['ğŸ¤—', 'Nakkalites back tooo form ahhhğŸ’•ğŸ˜˜ğŸ’•ğŸ’•ğŸ’•â¤â¤â¤â¤...  \n",
       "6         28            44                                       ['First â¤ğŸ‰']  \n",
       "7         25            43  ['ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚', 'Adutha Aapu Udane Nanbanukku thağŸ˜‚', ...  \n",
       "8         28            56  ['ğŸ˜‚ğŸ˜‚ğŸ˜‚', 'Hi ashwin, Amit this side  I liked wa...  \n",
       "9         25            51                                         ['SuperğŸ˜‚']  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15d9a22c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Nakkalites', 'Village Cooking Channel', 'Madan Gowri'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_data['channelTitle'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed23127d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Vasu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Vasu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Vasu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Vasu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "058ec3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lemmatizer and stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lzr = WordNetLemmatizer()\n",
    "\n",
    "# Text Preprocessing Function\n",
    "def text_processing(text):\n",
    "    # Basic preprocessing\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    text = re.sub(f'[{re.escape(punctuation)}]', '', text)\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "    \n",
    "    # Tokenize, remove stopwords and lemmatize\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    tokens = [lzr.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    return ' '.join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18c1f66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Sentiment Intensity Analyzer\n",
    "sentiments = SentimentIntensityAnalyzer()\n",
    "\n",
    "def analyze_channel_sentiment(channel_name, channel_data):\n",
    "    print(f\"Processing sentiment analysis for {channel_name}...\")\n",
    "\n",
    "    # Explode and preprocess comments\n",
    "    channel_data = channel_data.explode('comments').dropna(subset=['comments'])\n",
    "    channel_data['comments'] = channel_data['comments'].apply(lambda text: text_processing(text))\n",
    "\n",
    "    # Sentiment Analysis\n",
    "    channel_data[\"Positive\"] = [sentiments.polarity_scores(comment)[\"pos\"] for comment in channel_data[\"comments\"]]\n",
    "    channel_data[\"Negative\"] = [sentiments.polarity_scores(comment)[\"neg\"] for comment in channel_data[\"comments\"]]\n",
    "    channel_data[\"Neutral\"] = [sentiments.polarity_scores(comment)[\"neu\"] for comment in channel_data[\"comments\"]]\n",
    "    channel_data['Compound'] = [sentiments.polarity_scores(comment)[\"compound\"] for comment in channel_data[\"comments\"]]\n",
    "\n",
    "    score = channel_data[\"Compound\"].values\n",
    "    sentiment = []\n",
    "    for s in score:\n",
    "        if s >= 0.05:\n",
    "            sentiment.append('Positive')\n",
    "        elif s <= -0.05:\n",
    "            sentiment.append('Negative')\n",
    "        else:\n",
    "            sentiment.append('Neutral')\n",
    "\n",
    "    channel_data[\"Sentiment\"] = sentiment\n",
    "\n",
    "    # Dropping unnecessary columns\n",
    "    channel_data = channel_data.drop(['Positive', 'Negative', 'Neutral', 'Compound'], axis=1)\n",
    "\n",
    "    # Encoding Sentiment Labels\n",
    "    le = LabelEncoder()\n",
    "    channel_data['Sentiment'] = le.fit_transform(channel_data['Sentiment'])\n",
    "\n",
    "    # Upsampling Minority Classes\n",
    "    df_neutral = channel_data[channel_data['Sentiment'] == le.transform(['Neutral'])[0]]\n",
    "    df_negative = channel_data[channel_data['Sentiment'] == le.transform(['Negative'])[0]]\n",
    "    df_positive = channel_data[channel_data['Sentiment'] == le.transform(['Positive'])[0]]\n",
    "\n",
    "    df_negative_upsampled = resample(df_negative, replace=True, n_samples=len(df_positive), random_state=42)\n",
    "    df_neutral_upsampled = resample(df_neutral, replace=True, n_samples=len(df_positive), random_state=42)\n",
    "\n",
    "    # Concatenate the upsampled dataframes\n",
    "    final_data = pd.concat([df_negative_upsampled, df_neutral_upsampled, df_positive])\n",
    "\n",
    "    # Vectorization\n",
    "    corpus = final_data['comments'].tolist()\n",
    "    cv = CountVectorizer(max_features=1500)\n",
    "    X = cv.fit_transform(corpus).toarray()\n",
    "    y = final_data['Sentiment'].values\n",
    "\n",
    "    # Model Training\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluation\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    nb_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Results\n",
    "    print(f\"Sentiment Analysis Results for {channel_name}:\")\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    print(\"Accuracy:\", nb_score)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6982111a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sentiment analysis for Nakkalites...\n",
      "Sentiment Analysis Results for Nakkalites:\n",
      "Confusion Matrix:\n",
      " [[268   6  28]\n",
      " [  0 263  15]\n",
      " [ 11  34 245]]\n",
      "Accuracy: 0.8919540229885058\n",
      "\n",
      "\n",
      "Processing sentiment analysis for Village Cooking Channel...\n",
      "Sentiment Analysis Results for Village Cooking Channel:\n",
      "Confusion Matrix:\n",
      " [[63  0  0]\n",
      " [ 0 72  0]\n",
      " [ 0  0 73]]\n",
      "Accuracy: 1.0\n",
      "\n",
      "\n",
      "Processing sentiment analysis for Madan Gowri...\n",
      "Sentiment Analysis Results for Madan Gowri:\n",
      "Confusion Matrix:\n",
      " [[515  22  86]\n",
      " [  0 631   0]\n",
      " [182  36 389]]\n",
      "Accuracy: 0.8248253627082214\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "data = pd.read_csv('C:/Users/Vasu/Desktop/API projects/youtube_api/youtube_merged.csv')\n",
    "\n",
    "# List of channels\n",
    "channels = data['channelTitle'].unique()\n",
    "\n",
    "# Perform sentiment analysis for each channel\n",
    "for channel in channels:\n",
    "    channel_data = data[data['channelTitle'] == channel]\n",
    "    analyze_channel_sentiment(channel, channel_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c746c79b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
